{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from scipy.sparse import hstack, vstack, csr_matrix\n",
    "from scipy import sparse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Dense, Dropout, merge, concatenate\n",
    "from keras.layers import LSTM, Embedding, GRU\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras_tqdm import TQDMNotebookCallback, TQDMCallback\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, PassiveAggressiveClassifier, Perceptron\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, log_loss\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, mutual_info_classif, chi2, SelectFromModel\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import re\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#font = {'family': 'Verdana', 'weight': 'normal'}\n",
    "#rc('font', **font)\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spacy.util.set_data_path('/home/data/spacy/')\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('/home/data/share/quora/train.csv', index_col=0)\n",
    "test_set = pd.read_csv('/home/data/share/quora/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>When do you use シ instead of し?</td>\n",
       "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid1  qid2                                          question1  \\\n",
       "id                                                                  \n",
       "0      1     2  What is the step by step guide to invest in sh...   \n",
       "1      3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2      5     6  How can I increase the speed of my internet co...   \n",
       "3      7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4      9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "5     11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "6     13    14                                Should I buy tiago?   \n",
       "7     15    16                     How can I be a good geologist?   \n",
       "8     17    18                    When do you use シ instead of し?   \n",
       "9     19    20  Motorola (company): Can I hack my Charter Moto...   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "id                                                                   \n",
       "0   What is the step by step guide to invest in sh...             0  \n",
       "1   What would happen if the Indian government sto...             0  \n",
       "2   How can Internet speed be increased by hacking...             0  \n",
       "3   Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4             Which fish would survive in salt water?             0  \n",
       "5   I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "6   What keeps childern active and far from phone ...             0  \n",
       "7           What should I do to be a great geologist?             1  \n",
       "8               When do you use \"&\" instead of \"and\"?             0  \n",
       "9   How do I hack Motorola DCX3400 for free internet?             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ответы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtwAAAF2CAYAAABdxk98AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd01298fc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set.hist(column='is_duplicate', bins=2, figsize=(12, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = train_set['is_duplicate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пробелы в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105780</th>\n",
       "      <td>174363</td>\n",
       "      <td>174364</td>\n",
       "      <td>How can I develop android app?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201841</th>\n",
       "      <td>303951</td>\n",
       "      <td>174364</td>\n",
       "      <td>How can I create an Android app?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid1    qid2                         question1 question2  \\\n",
       "id                                                                   \n",
       "105780  174363  174364    How can I develop android app?       NaN   \n",
       "201841  303951  174364  How can I create an Android app?       NaN   \n",
       "\n",
       "        is_duplicate  \n",
       "id                    \n",
       "105780             0  \n",
       "201841             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[train_set.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379205</th>\n",
       "      <td>How I can learn android app development?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817520</th>\n",
       "      <td>How real can learn android app development?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943911</th>\n",
       "      <td>How app development?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046690</th>\n",
       "      <td>NaN</td>\n",
       "      <td>How I what can learn android app development?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270024</th>\n",
       "      <td>How I can learn app development?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461432</th>\n",
       "      <td>NaN</td>\n",
       "      <td>How distinct can learn android app development?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "test_id                                                \n",
       "379205      How I can learn android app development?   \n",
       "817520   How real can learn android app development?   \n",
       "943911                          How app development?   \n",
       "1046690                                          NaN   \n",
       "1270024             How I can learn app development?   \n",
       "1461432                                          NaN   \n",
       "\n",
       "                                               question2  \n",
       "test_id                                                   \n",
       "379205                                               NaN  \n",
       "817520                                               NaN  \n",
       "943911                                               NaN  \n",
       "1046690    How I what can learn android app development?  \n",
       "1270024                                              NaN  \n",
       "1461432  How distinct can learn android app development?  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[test_set.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set.fillna('empty_string', inplace=True)\n",
    "test_set.fillna('empty_string', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404283</th>\n",
       "      <td>537924</td>\n",
       "      <td>537925</td>\n",
       "      <td>What do you think of the removal of the MagSaf...</td>\n",
       "      <td>What will the CPU upgrade to the 2016 Apple Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404284</th>\n",
       "      <td>537926</td>\n",
       "      <td>537927</td>\n",
       "      <td>What does Jainism say about homosexuality?</td>\n",
       "      <td>What does Jainism say about Gays and Homosexua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid1    qid2                                          question1  \\\n",
       "id                                                                          \n",
       "0            1       2  What is the step by step guide to invest in sh...   \n",
       "1            3       4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2            5       6  How can I increase the speed of my internet co...   \n",
       "3            7       8  Why am I mentally very lonely? How can I solve...   \n",
       "4            9      10  Which one dissolve in water quikly sugar, salt...   \n",
       "5           11      12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "6           13      14                                Should I buy tiago?   \n",
       "...        ...     ...                                                ...   \n",
       "404283  537924  537925  What do you think of the removal of the MagSaf...   \n",
       "404284  537926  537927         What does Jainism say about homosexuality?   \n",
       "404285  433578  379845  How many keywords are there in the Racket prog...   \n",
       "404286   18840  155606          Do you believe there is life after death?   \n",
       "404287  537928  537929                                  What is one coin?   \n",
       "404288  537930  537931  What is the approx annual cost of living while...   \n",
       "404289  537932  537933              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "id                                                                       \n",
       "0       What is the step by step guide to invest in sh...             0  \n",
       "1       What would happen if the Indian government sto...             0  \n",
       "2       How can Internet speed be increased by hacking...             0  \n",
       "3       Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4                 Which fish would survive in salt water?             0  \n",
       "5       I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "6       What keeps childern active and far from phone ...             0  \n",
       "...                                                   ...           ...  \n",
       "404283  What will the CPU upgrade to the 2016 Apple Ma...             0  \n",
       "404284  What does Jainism say about Gays and Homosexua...             1  \n",
       "404285  How many keywords are there in PERL Programmin...             0  \n",
       "404286         Is it true that there is life after death?             1  \n",
       "404287                                  What's this coin?             0  \n",
       "404288  I am having little hairfall problem but I want...             0  \n",
       "404289      What is it like to have sex with your cousin?             0  \n",
       "\n",
       "[404290 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Множества(train, test, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load tokenized questions\n",
    "train_q1_tokenized_objects = load_tokenized_series('train_q1_tokenized.csv')\n",
    "train_q2_tokenized_objects = load_tokenized_series('train_q2_tokenized.csv')\n",
    "test_q1_tokenized_objects = load_tokenized_series('test_q1_tokenized.csv')\n",
    "test_q2_tokenized_objects = load_tokenized_series('test_q2_tokenized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_index = train_q1_tokenized_objects.index\n",
    "train_pairs = pd.DataFrame(index=train_index)\n",
    "train_pairs['question1'] = train_q1_tokenized_objects\n",
    "train_pairs['question2'] = train_q2_tokenized_objects\n",
    "train_pairs = train_pairs.values\n",
    "\n",
    "test_index = test_q1_tokenized_objects.index\n",
    "test_pairs = pd.DataFrame(index=test_index)\n",
    "test_pairs['question1'] = test_q1_tokenized_objects\n",
    "test_pairs['question2'] = test_q2_tokenized_objects\n",
    "test_pairs = test_pairs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tokens, validation_tokens, y_train, y_validation = train_test_split(train_pairs, Y_train.values,\n",
    "                                                                          test_size=0.1, random_state=42)\n",
    "test_tokens = test_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=200000)\n",
    "all_questions = np.concatenate([train_set['question1'].values,\n",
    "                                train_set['question2'].values,\n",
    "                                test_set['question1'].values,\n",
    "                                test_set['question2'].values])\n",
    "\n",
    "tokenizer.fit_on_texts(all_questions)\n",
    "\n",
    "train_question1_sequences = tokenizer.texts_to_sequences(train_set['question1'].values)\n",
    "train_question2_sequences = tokenizer.texts_to_sequences(train_set['question2'].values)\n",
    "test_question1_sequences = tokenizer.texts_to_sequences(test_set['question1'].values)\n",
    "test_question2_sequences = tokenizer.texts_to_sequences(test_set['question2'].values)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec squence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def space_tokenizer(s):\n",
    "    return s.split(' ')\n",
    "\n",
    "def text_from_tokens_spacy(tokens):\n",
    "    tokens = [token.lower_ for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_parh = os.path.join(os.sep, os.path.abspath('/home/data/word2vec/english/GoogleNews-vectors-negative300.bin'))\n",
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(w2v_parh, binary=True)\n",
    "w2v.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_to_embeddings(text):\n",
    "    sequence = [w2v.syn0norm[w2v.vocab[token].index] for token in space_tokenizer(text) if word in w2v.vocab]\n",
    "\n",
    "    if not sequence:\n",
    "        return np.zeros(300)\n",
    "\n",
    "    return np.concatenate(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_to_integers(tokens, vocabulary):\n",
    "    return [vocabulary[token]+1 if token in vocabulary else 0 for token in tokens if token in vocabulary]\n",
    "\n",
    "def get_vocabulary(texts, min_df=1):\n",
    "    count_vectorizer = CountVectorizer(analyzer=\"word\", lowercase=False, tokenizer=space_tokenizer, min_df=min_df, binary=True)\n",
    "    count_vectorizer = count_vectorizer.fit(texts)\n",
    "    vocabulary = count_vectorizer.vocabulary_\n",
    "    \n",
    "    return vocabulary\n",
    "    \n",
    "def texts_to_integers(texts, vocabulary):\n",
    "    sequences = [tokens_to_integers(text.split(' '), vocabulary) for text in texts]\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_texts = np.concatenate([train_pairs[:, 0], train_pairs[:, 1]])\n",
    "\n",
    "vocab = get_vocabulary(all_texts)\n",
    "vocab_len = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sequences = train_tokens.copy()\n",
    "train_sequences[:, 0] = texts_to_integers(train_sequences[:, 0], vocab)\n",
    "train_sequences[:, 1] = texts_to_integers(train_sequences[:, 1], vocab)\n",
    "\n",
    "validation_sequences = validation_tokens.copy()\n",
    "validation_sequences[:, 0] = texts_to_integers(validation_sequences[:, 0], vocab)\n",
    "validation_sequences[:, 1] = texts_to_integers(validation_sequences[:, 1], vocab)\n",
    "\n",
    "test_sequences = test_tokens.copy()\n",
    "test_sequences[:, 0] = texts_to_integers(test_sequences[:, 0], vocab)\n",
    "test_sequences[:, 1] = texts_to_integers(test_sequences[:, 1], vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-935c3dc3782a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0membedding_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Null word embeddings: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word_embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300\n",
    "embedding_weights = np.zeros((vocab_len+1, embedding_dim))\n",
    "for word, index in vocab.items():\n",
    "    if word in w2v.vocab:\n",
    "        embedding_weights[index, :] = w2v.syn0norm[w2v.vocab[word].index] \n",
    "        \n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_weights, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, question 1:\n",
      "\tMax: 152, Min: 1, Mean: 12.613437548954133, percentile 0.95: 25.0\n",
      "Train, question 2:\n",
      "\tMax: 271, Min: 1, Mean: 12.886632532752891, percentile 0.95: 27.0\n",
      "\n",
      "\n",
      "Validation, question 1:\n",
      "\tMax: 77, Min: 1, Mean: 12.644141581538005, percentile 0.95: 25.0\n",
      "Validation, question 2:\n",
      "\tMax: 269, Min: 1, Mean: 12.843206609117217, percentile 0.95: 27.0\n",
      "\n",
      "\n",
      "Test, question 1:\n",
      "\tMax: 272, Min: 0, Mean: 12.665855001884221, percentile 0.95: 26.0\n",
      "Test, question 2:\n",
      "\tMax: 274, Min: 0, Mean: 12.702333450990624, percentile 0.95: 27.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lens = [len(l) for l in train_sequences[:, 0]]\n",
    "print('Train, question 1:')\n",
    "print('\\tMax: {}, Min: {}, Mean: {}, percentile 0.95: {}'.format(max(lens), min(lens), np.mean(lens), np.percentile(lens, 95)))\n",
    "\n",
    "lens = [len(l) for l in train_sequences[:, 1]]\n",
    "print('Train, question 2:')\n",
    "print('\\tMax: {}, Min: {}, Mean: {}, percentile 0.95: {}'.format(max(lens), min(lens), np.mean(lens), np.percentile(lens, 95)))\n",
    "print('\\n')\n",
    "\n",
    "lens = [len(l) for l in validation_sequences[:, 0]]\n",
    "print('Validation, question 1:')\n",
    "print('\\tMax: {}, Min: {}, Mean: {}, percentile 0.95: {}'.format(max(lens), min(lens), np.mean(lens), np.percentile(lens, 95)))\n",
    "\n",
    "lens = [len(l) for l in validation_sequences[:, 1]]\n",
    "print('Validation, question 2:')\n",
    "print('\\tMax: {}, Min: {}, Mean: {}, percentile 0.95: {}'.format(max(lens), min(lens), np.mean(lens), np.percentile(lens, 95)))\n",
    "print('\\n')\n",
    "\n",
    "lens = [len(l) for l in test_sequences[:, 0]]\n",
    "print('Test, question 1:')\n",
    "print('\\tMax: {}, Min: {}, Mean: {}, percentile 0.95: {}'.format(max(lens), min(lens), np.mean(lens), np.percentile(lens, 95)))\n",
    "\n",
    "lens = [len(l) for l in test_sequences[:, 1]]\n",
    "print('Test, question 2:')\n",
    "print('\\tMax: {}, Min: {}, Mean: {}, percentile 0.95: {}'.format(max(lens), min(lens), np.mean(lens), np.percentile(lens, 95)))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 45\n",
    "\n",
    "train_sequences_q1 = sequence.pad_sequences(train_sequences[:, 0], maxlen=maxlen)\n",
    "train_sequences_q2 = sequence.pad_sequences(train_sequences[:, 1], maxlen=maxlen)\n",
    "train_sequences = np.array([pair for pair in list(zip(train_sequences_q1, train_sequences_q2))])\n",
    "del train_sequences_q1, train_sequences_q2\n",
    "\n",
    "validation_sequences_q1 = sequence.pad_sequences(validation_sequences[:, 0], maxlen=maxlen)\n",
    "validation_sequences_q2 = sequence.pad_sequences(validation_sequences[:, 1], maxlen=maxlen)\n",
    "validation_sequences = np.array([pair for pair in list(zip(validation_sequences_q1, validation_sequences_q2))])\n",
    "del validation_sequences_q1, validation_sequences_q2\n",
    "\n",
    "test_sequences_q1 = sequence.pad_sequences(test_sequences[:, 0], maxlen=maxlen)\n",
    "test_sequences_q2 = sequence.pad_sequences(test_sequences[:, 1], maxlen=maxlen)\n",
    "test_sequences = np.array([pair for pair in list(zip(test_sequences_q1, test_sequences_q2))])\n",
    "del test_sequences_q1, test_sequences_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((363861, 2, 45), (40429, 2, 45), (2345796, 2, 45))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences.shape, validation_sequences.shape, test_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_sequences\n",
    "x_validation = validation_sequences\n",
    "x_test = test_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features, embedding_dim, maxlen = vocab_len+1, 300, maxlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(Q1, Q2, Y, batch_size, shuffle=False):\n",
    "    n = Y.shape[0]\n",
    "    number_of_batches, counter, shuffle_index = n//batch_size, 0, np.arange(n)\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(shuffle_index)\n",
    "\n",
    "    Q1, Q2, Y =  Q1[shuffle_index], Q2[shuffle_index], Y[shuffle_index]\n",
    "    \n",
    "    while True:\n",
    "        for counter in range(number_of_batches+1):\n",
    "            index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
    "            X, Y_batch = [Q1[index_batch], Q2[index_batch]], Y[index_batch]\n",
    "            yield X, Y_batch\n",
    "            \n",
    "        if shuffle:\n",
    "            np.random.shuffle(shuffle_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_representation(input_shape):\n",
    "    representation = Sequential()\n",
    "    representation.add(Embedding(max_features, embedding_dim, input_length=input_shape, weights=[embedding_weights]))\n",
    "    representation.add(LSTM(embedding_dim))\n",
    "    \n",
    "    return representation\n",
    "\n",
    "def build_model(question_shape):\n",
    "    first_question = Input(shape=(question_shape, ))\n",
    "    second_question = Input(shape=(question_shape, ))\n",
    "    \n",
    "    representation = get_representation(question_shape)\n",
    "    \n",
    "    first_representation = representation(first_question)\n",
    "    second_representation = representation(second_question)\n",
    "    \n",
    "    merged_vectors = concatenate([first_representation, second_representation])\n",
    "    output_proba = Dense(1, activation='sigmoid', kernel_initializer='he_normal')(merged_vectors)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[first_question, second_question],\n",
    "        outputs=output_proba\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def get_nn_model(*, path_to_hdf5=False, input_shape=None):\n",
    "    model = build_model(input_shape) \n",
    "    #optimizer = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # load pretrained weights\n",
    "    if path_to_hdf5:\n",
    "        model.load_weights(path_to_hdf5)\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "filepath=\"weights_{epoch:02d}_{val_loss:.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=1, mode='min')\n",
    "callbacks_list = [checkpoint, early_stopping, TQDMNotebookCallback()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_11 (InputLayer)            (None, 45)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_12 (InputLayer)            (None, 45)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)        (None, 300)           26892000                                     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 600)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             601                                          \n",
      "====================================================================================================\n",
      "Total params: 26,892,601\n",
      "Trainable params: 26,892,601\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed widget Javascript is the wrong version.\n",
      "The installed widget Javascript is the wrong version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/5\n",
      "Epoch 00000: val_loss improved from inf to 0.48899, saving model to weights_00_0.489.hdf5\n",
      "119s - loss: 0.5172 - acc: 0.7453 - val_loss: 0.4890 - val_acc: 0.7669\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed widget Javascript is the wrong version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00001: val_loss did not improve\n",
      "121s - loss: 0.4393 - acc: 0.7930 - val_loss: 0.4961 - val_acc: 0.7657\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed widget Javascript is the wrong version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00002: val_loss did not improve\n",
      "181s - loss: 0.3663 - acc: 0.8299 - val_loss: 0.5715 - val_acc: 0.7594\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed widget Javascript is the wrong version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00003: val_loss did not improve\n",
      "249s - loss: 0.2966 - acc: 0.8628 - val_loss: 0.6633 - val_acc: 0.7510\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed widget Javascript is the wrong version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: val_loss did not improve\n",
      "248s - loss: 0.2578 - acc: 0.8812 - val_loss: 0.8098 - val_acc: 0.7628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "steps_per_epoch = y_train.shape[0]//batch_size\n",
    "validation_steps = y_validation.shape[0]//batch_size\n",
    "input_shape = maxlen\n",
    "\n",
    "train_generator = batch_generator(x_train[:, 0], x_train[:, 1], y_train, batch_size, shuffle=False)\n",
    "validation_generator = batch_generator(x_validation[:, 0], x_validation[:, 1], y_validation, batch_size, shuffle=False)\n",
    "\n",
    "model = get_nn_model(input_shape=input_shape)\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=validation_steps,\n",
    "                              epochs=5, verbose=2, callbacks=callbacks_list,\n",
    "                              max_q_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
